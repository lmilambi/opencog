
    Diary of MOSES performance and Enhancement Work
    -----------------------------------------------
       Linas Vepstas -- started June 2014


Diary of notes, thoughts, measurements, pertaining to work on MOSES.

Boosting in MOSES
-----------------
There are several very different ways of envisioning boosting in MOSES,
each being more or less compatible with the formal definition of
boosting. See http://en.wikipedia.org/wiki/Boosting_(meta-algorithm)

(Caution: the formulas in http://en.wikipedia.org/wiki/AdaBoost
are incorrect and misleading, and suggests an inapprorpriate algorithm
and implementation. Beware!)

The formal definition of boosting invokes the idea of a weighted
ensemble of 'weak learners'.  Each member of the ensemble is given a
weight, with the weights being issued so as to minimize the total error
of the prediction being made by the ensemble. The accuracy of the
ensemble is then measured, and used to identify those samples in the
training set that are being classified incorrectly.  New weak learners
are then trained, with an emphasis on correctly classifying those
samples that were gotten incorrect by the ensemble.

For MOSES, it appropriate definition of 'ensemble' is ambiguous.
The ensemble can be: 

  A) The set of instances in the current deme
  B) The evolutionary history of a given exemplar
  C) The collection of combo trees (exemplars) in the metapopulation.
  D) Some combination of the above.

Let's recall the definition of an exemplar, a deme, and a
metapopulation.

 *) An 'exemplar' is a single, fixed combo tree.  It has some
    evolutionary heritage, having evolved from earlier trees.

 *) The metapopulation is the current collection of the fittest
    (most accurate) exemplars.

 *) A deme is an exemplar that has been decorated with knobs, together
    with a large set of possible knob settings (instances).  Each
    instance is conceptually a single combo tree, that differs
    structurally from its parent exemplar in some 'minor' way.

Lets look at how the boosting algo would work for each scenario. But
first, lets sketch the current 'hill-climbing' algo, as currently
performed by MOSES.

--------------
Hill-climbing) The current canonical algo.

 H.1) Select an exemplar from the metapopulation, create deme.
 H.2) Generate N instances by turning N knobs.
 H.3) Score all N instances, using a uniform weight on all samples.
 H.4) Select the highest-scoring instance. (this is the hill-climb).
 H.5) Go to step H.2

 H.6) Terminate above loop in some way. (e.g. top of hill reached)
 H.7) Put M of the top-scoring instances into the metapopulation.
 H.8) Go to step H.1

 H.9) Terminate above loop in some way.
 H.10) Use the top K exemplars in the metapopulation to create a
       traditional ensemble, for off-line prediction/classification.


--------------
Scenario A) The set of instances is an ensemble.  In this scenario, the
boosting algorithm becomes a variant the current 'hill-climbing' algo.
The steps are numbered below so that they correspond to the
hill-climbing steps. To summarize: step H.3 is replaced by the Boost
algo, so that H.3 is a bunch of steps.

 A.1) Select an exemplar from the metapopulation. (same as H.1)
 A.2) Generate N instances by turning N knobs. (same as H.2)
 A.3.1) Score all N instances, using a uniform weight on all samples.
 A.3.2) Pick the best instance, per boost, add it to the ensemble.
 A.3.3) Adjust per-sample weight based on ensemble mis-prediction
 A.3.4) Re-score remaining N-1 instances with new weighted scorer.
 A.3.5) Go to step A.3.2

 A.3.7) Terminate above loop using some criteria,
 A.4) Select the highest-scoring instance, based on the weighted
      scorer available at termination time.
 A.5) Go to step A.2 (Same as H.5)

 A.6.1) Terminate above loop in some way. (e.g. top of hill reached)
 A.6.2) Discard all row-weights.
 A.7) Put M of the top-scoring instances into metapop.  (Same as H.7)
 A.8) Go to step A.1 (Same as H.8)

 A.9) Same as H.9
 A.10) Same as H.10

The above seems to make sense, and superfically seems to be compatible
with the formal definition of boosting.  However, step A.4 seems somewhat
strange. Lets ponder this.

In step A.4, we pick the instance with the highest weighted score,
rather than the instance with the highest overall accuracy. What does
this mean?  What effect does this have?  Well, it selects for an
instance that gets right what previous instances got wrong.  By the time
that we get past step A.7, what we've done is to create M exemplars that
got things right that the initial exemplar did not.  Do any of these M
exemplars have a better absolute value accuracy score than the initial
exemplar? Unclear, possibly not.  So we have research question 1:

 RQ.1) Compare the 'raw' score of the M exemplars from step A.7 to the
       score from ordinary hill-climbing H.7.  Is it possible that the
       weighted hill-climb of step A.4 somehow avoided a plateau that
       H.4 may have gotten stuck in?  viz. Can scenario A) boosting
       actually outperform ordinary hill-climbing? (At each step?)

 RQ.2) Is the final metapopulation of A.10 stronger/fitter/better than
       that of H.10, given same amount of CPU time?  (Hill-climbing is
       less CPU intensive, so can perform more iterations).

--------------
Secnario B) The ensemble is the evolutionary history of an exemplar.

There's actually two Scenario B's. So:

----
Scenario Ba) Just like Scenario A, except that at step A.6.2, we save
the final weights, associate them with this particular exemplar.  These
weights are then used in step A.3.1, instead of a uniform distribution.

This begs the question:
  RQ.3) Is scenario Ba better than plain-A?  It seems to offer some kind
        of continuinty with what came before, but does that matter?  The
        only reason the top-of-hill A.6.1 is evaded is because the knobs
        are all different ...

----
Scenario Bh) Just like plain-old hill-climbing H, except that steps H.3
and H.7 are modified. Step H.7 is replaced by the boost algo, with step
H.3 using the appropriate boosting scoring function.

 Bh.1) Select an exemplar from the metapopulation. (Same as H.1)
 Bh.2) Generate N instances by turning N knobs. (Same as H.2)
 Bh.3x) Score all N instances, using a weight distribution that was
        previously saved with the exemplar.
 Bh.4) Select the highest-scoring instance. (Same as H.4)
 Bh.5) Go to step Bh.2 (Same as H.5)

 Bh.6) Terminate above loop in some way. (e.g. top of hill reached)
 Bh.7.1) Select M top-scoring instances. 
 Bh.7.2) Add that instance to an ensemble that contains its parent.
 Bh.7.3) Update row weights for this ensemble.
 Bh.7.4) Place the ensemble into the metapopulation.
 Bh.8) Go to step Bh.1 (Same as step H.8)

Here, the ensemble consists only of an exemplar, and all of its parents
from which it is descended.  These seems to be rather thin.  The problem
is that step 6-8 don't happen that often -- and so the ensembles never
get very big.  Naively, boosting would seem to work best when the
ensembles have many members. This begs the question:

 RQ.4) How big to the ensembles get, for the Bh approach?

and 
 RQ.5) Same as RQ.2 -- net-net, is this better?

--------------
Secnario C) Maintain an ensemble drawn from the metapopulation.

Again, this is a variant of the canonical hill-climbing algo, with
modifications show below.  To summarize, step H.7 is replaced by the
boost algo.  Unlike Bh.7, though, the ensemble is drawn from the
entire metapop.

 C.1) Select an exemplar from the metapopulation. (Same as H.1)
 C.2) Generate N instances by turning N knobs. (Same as H.2)
 C.3x) Score all N instances, using weighted scorer.
 C.4) Select the highest-scoring instance. (Same as H.4)
 C.5) Go to step C.2 (Same as H.5)

 C.6) Terminate above loop in some way. (Same as H.6)
 C.7.1) From 1 till M, do:
 C.7.2) Pick the best instance, per boost, add it to the ensemble.
 C.7.3) Adjust per-sample weight based on instance mis-prediction.
 C.7.5) Re-score remaining M-1 instances with new weighted scorer.
 C.7.6) Place all instances into the metapop.
 C.7.7) Go to step C.7.2

 C.8) Go to step C.1 (Same as H.8)

 C.9) Terminate above loop in some way. (Same as H.9)
 C.10) Use the ensemble built in step C.7.2 as the final output of
       the process. i.e. The ensemble is what is finally used for
       off-line prediction/classification.

Senario C appears to be the one that is closest in spirit to the 
traditional boosting algos, and thus will be implemented first.

Scenario C does have interesting issues with the metapopulation
management.  With each iteration, the scoring criteria for managing the
metapopulation will change, and the metapop will contain a mixture of
trees from earlier rounds, and the current round.  This poses a
question: 

 RQ.6) Should the metapop be rescored with the new re-weighted scorer,
       or is it OK to leave stale score in there?

Design issues
-------------
How to implement Scenario C:
- Add single weight to scored combo tree. 

- Maintain a weight column .. where? In a new boosing scorer.
  Needs to be like the behave_cscore, but different.

Scoring Requirements:
1) hill-climber needs a *single* scalar score, to determine which way is "up".
2) This scalar score needs to be a sum of:
   a) a complexity penalty, obtained from the combo tree,
   b) a diversity penalty, based on
      i) the metapopulation
      ii) possibly the behavioral score
      iii) possibly the combo tree
   c) a function of the behavioral score, such as a direct sum,
      or possibly a weighted bscore (e.g. via boosting).

3) Multiple tables will be explicitly NOT supported. Why? Because its
   not clear how to combine these.  One way would be to combine them
   into one big table.  Another possibility is to use a different
   bscorer on each; but I don't know of a use-case for that.  I don't
   know how to weight these relative to one-another.  So, for now, 
   bonly one table.

Solution:
-- remove multibscore (done)
-- provide a utility for #2 that assembles a composite score from the 
   parts, and can be queried for the scalar score. Done: its behave_cscore.

Notes/TODO:
-- complexity is not being factored in ... 
-- scorer is currently not using the user-specified wight column !?
   or are those in the bscores already?

loop termination is on mp.best_score

Problems:
1) best score must now be the ensemble score.
2) the "update best cands" is no longer trying to beat the best in the
   metapop, because the criteria for "best" haas changed.  This seems to
   mean that the entire metapop needs to be rescored.  Maybe leave this
   as open question.





What is a deme_t?

typedef instance_set<composite_score> deme_t;
struct instance_set : public vector<scored_instance<ScoreT> >
All instances in instance set have same field description.

why is there ever more than one instance set??

==============

24 June 2014
------------
Compare the boosted & non-boosted version of the parity problem.

Time to perfect score:
time moses -Hpa -k3 --boost=1  : 1/2 second
time moses -Hpa -k4 --boost=1  : 1.8 seconds
time moses -Hpa -k5 --boost=1  : 9.2 seconds
time moses -Hpa -k6 --boost=1  : 6m13 seconds

Wow!  Recall that without boosting, -k4 would take minutes, (depending
very strongly on the initial random seed) and that -k5 was mostly 
unsolvable (would take an hour or two for a few lucky random seeds)

Wow, even -k6 finds a solution, although it is long, and takes much
more time to find.   ... and needs to have --reveist=50

So: -k4 speedup == 100x roughly
    -k5 sppedup == more than 500x

Hmm  different rand seeds:

           -k4     -k5      -k6
 random    time    time     time
  seed    (secs)  (secs)   (secs)
 ------   ------  ------   ------
   r0      1.8      11.2     568
   r1      1.8       9.2     392
   r2      2.5      10.4     190
   r3      2.6      11.8     260
   r4      2.3       9.2     260
   r5      2.2      18.0    2385
   r6      1.8      12.7     152
   r7      2.6      13.5    2360
   r8      2.0      12.3     501
   r9      2.0       9.9    1207

